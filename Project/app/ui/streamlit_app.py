# app/ui/streamlit_app_final.py
import streamlit as st
import requests
import json
import os
import time
import uuid
from typing import Dict, Any, List, Optional

# Set page configuration
st.set_page_config(
    page_title="Document Intelligence RAG Chatbot",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# API URL
API_BASE_URL = "http://localhost:8000"

# Set to True to use the real API, False to use mock
USE_REAL_API = True

# Functions for API interactions
def upload_document(file):
    """Upload a document to the embedding API"""
    if USE_REAL_API:
        try:
            files = {"document": file}
            response = requests.post(f"{API_BASE_URL}/api/embedding", files=files)
            return response.json()
        except requests.exceptions.ConnectionError:
            st.error(f"‚ö†Ô∏è Could not connect to API at {API_BASE_URL}. Using mock mode instead.")
            return mock_upload_document(file)
    else:
        return mock_upload_document(file)

def query_document(query: str, document_id: str, conversation_id: Optional[str] = None, require_citations: bool = True):
    """Query a document using the query API"""
    if USE_REAL_API:
        try:
            payload = {
                "query": query,
                "document_id": document_id,
                "require_citations": require_citations
            }
            
            if conversation_id:
                payload["conversation_id"] = conversation_id
            
            response = requests.post(f"{API_BASE_URL}/api/query", json=payload)
            return response.json()
        except requests.exceptions.ConnectionError:
            st.error(f"‚ö†Ô∏è Could not connect to API at {API_BASE_URL}. Using mock mode instead.")
            return mock_query_document(query, document_id, conversation_id, require_citations)
    else:
        return mock_query_document(query, document_id, conversation_id, require_citations)

# Mock functions (backup if API is not available)
def mock_upload_document(file):
    """Mock document upload function"""
    time.sleep(2)
    return {
        "status": "success",
        "message": "Document embedded successfully (MOCK MODE).",
        "document_id": str(uuid.uuid4())
    }

def mock_query_document(query: str, document_id: str, conversation_id: Optional[str] = None, require_citations: bool = True):
    """Mock query function"""
    time.sleep(2)
    answer = f"[MOCK MODE] This is a simulated answer to your question: '{query}'. In an actual deployment, this would be generated by the LLM based on document content."
    
    citations = []
    if require_citations:
        citations = [{"page": 1, "document_name": "Mock Document"}]
    
    conversation_id = conversation_id or str(uuid.uuid4())
    
    return {
        "status": "success",
        "response": {
            "answer": answer,
            "citations": citations
        },
        "conversation_id": conversation_id
    }

# Check API status
def check_api_status():
    """Check if the API is available"""
    try:
        response = requests.get(f"{API_BASE_URL}/health", timeout=3)
        if response.status_code == 200:
            return True
        return False
    except:
        return False

# Main application
def main():
    # Custom CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
        margin-bottom: 1rem;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border: 1px solid #E0E0E0;
    }
    .user-message {
        background-color: #E3F2FD;
        color: #333333; /* Dark text for contrast */
    }
    .assistant-message {
        background-color: #F5F5F5;
        color: #333333; /* Dark text for contrast */
    }
    .citation {
        background-color: #FFF8E1;
        padding: 0.5rem;
        border-radius: 0.3rem;
        font-size: 0.8rem;
        margin-top: 0.5rem;
        color: #5D4037; /* Brown text for citations */
    }
    </style>
    """, unsafe_allow_html=True)
        
    # Check API status and set mode
    global USE_REAL_API
    api_status = check_api_status()
    if not api_status:
        USE_REAL_API = False
    
    # Application header
    st.markdown("<h1 class='main-header'>Document Intelligence RAG Chatbot</h1>", unsafe_allow_html=True)
    
    # API status indicator
    if USE_REAL_API:
        st.success("‚úÖ Connected to API - Using real RAG functionality")
    else:
        st.warning("‚ö†Ô∏è API not connected - Using simulation mode")
    
    st.markdown("Upload documents and ask questions to get accurate, contextual responses with citations.")
    
    # Sidebar for document upload and management
    with st.sidebar:
        st.markdown("<h2 class='sub-header'>Document Management</h2>", unsafe_allow_html=True)
        
        # Document upload
        st.subheader("Upload Document")
        uploaded_file = st.file_uploader("Choose a document", type=["pdf", "docx", "txt"])
        
        if uploaded_file is not None:
            if st.button("Process Document"):
                with st.spinner("Processing document..."):
                    # Save uploaded file temporarily
                    with open(f"temp_{uploaded_file.name}", "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    
                    # Upload to API
                    with open(f"temp_{uploaded_file.name}", "rb") as f:
                        result = upload_document(f)
                    
                    # Clean up temp file
                    os.remove(f"temp_{uploaded_file.name}")
                    
                    if result.get("status") == "success":
                        st.success(f"Document processed successfully!")
                        st.session_state.document_id = result.get("document_id")
                        st.session_state.document_name = uploaded_file.name
                        st.session_state.messages = []  # Reset messages for new document
                        st.session_state.conversation_id = None  # Reset conversation
                    else:
                        st.error(f"Error processing document: {result.get('error_details', 'Unknown error')}")
        
        # Document selection (if we had multiple documents)
        if hasattr(st.session_state, 'document_id'):
            st.subheader("Current Document")
            st.info(f"Document: {st.session_state.document_name}\nID: {st.session_state.document_id}")
            
            # Option to clear current document
            if st.button("Clear Document"):
                if hasattr(st.session_state, 'document_id'):
                    del st.session_state.document_id
                    del st.session_state.document_name
                    st.session_state.messages = []
                    st.session_state.conversation_id = None
                    st.rerun()
            
            # Add a "Clear Conversation" button to reset conversation without changing document
            if hasattr(st.session_state, 'messages') and len(st.session_state.messages) > 0:
                if st.button("Clear Conversation"):
                    st.session_state.messages = []
                    st.session_state.conversation_id = None
                    st.rerun()
        
        # Settings
        st.subheader("Settings")
        require_citations = st.checkbox("Require Citations", value=True)
        
        # Message display settings
        if hasattr(st.session_state, 'messages') and len(st.session_state.messages) > 0:
            st.subheader("Display Settings")
            max_messages = st.slider("Max Messages to Display", 
                                    min_value=3, 
                                    max_value=20, 
                                    value=5, 
                                    help="Adjust how many recent messages to show")
        else:
            max_messages = 5  # Default if no messages yet
        
        # Mode toggle
        st.subheader("Mode")
        use_mock = st.checkbox("Use Mock Mode (No API)", value=not USE_REAL_API)
        if use_mock != (not USE_REAL_API):
            USE_REAL_API = not use_mock
            st.rerun()
    
    # Main chat interface
    if hasattr(st.session_state, 'document_id'):
        # Initialize messages if not exists
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        
        # Initialize conversation_id if not exists
        if 'conversation_id' not in st.session_state:
            st.session_state.conversation_id = None
        
        # Display chat messages with a limit
        if st.session_state.messages:
            st.markdown("<h2 class='sub-header'>Conversation</h2>", unsafe_allow_html=True)
            
            # Only display the most recent messages based on the slider
            recent_messages = st.session_state.messages[-max_messages:] if len(st.session_state.messages) > max_messages else st.session_state.messages
            
            # Add a "Show Full History" expander if there are hidden messages
            if len(st.session_state.messages) > max_messages:
                view_all = st.expander("Show Full Conversation History")
                with view_all:
                    for message in st.session_state.messages:
                        if message["role"] == "user":
                            st.markdown(f"<div class='chat-message user-message'><strong>You:</strong> {message['content']}</div>", unsafe_allow_html=True)
                        else:
                            # Display assistant message with citations
                            response_text = message["content"]
                            citations_html = ""
                            
                            if "citations" in message and message["citations"]:
                                citations_html = "<div class='citation'><strong>Citations:</strong><ul>"
                                for citation in message["citations"]:
                                    citations_html += f"<li>{citation['document_name']}, Page {citation['page']}</li>"
                                citations_html += "</ul></div>"
                            
                            st.markdown(f"<div class='chat-message assistant-message'><strong>Assistant:</strong> {response_text}{citations_html}</div>", unsafe_allow_html=True)
            
            # Display the limited recent messages
            for message in recent_messages:
                if message["role"] == "user":
                    st.markdown(f"<div class='chat-message user-message'><strong>You:</strong> {message['content']}</div>", unsafe_allow_html=True)
                else:
                    # Display assistant message with citations
                    response_text = message["content"]
                    citations_html = ""
                    
                    if "citations" in message and message["citations"]:
                        citations_html = "<div class='citation'><strong>Citations:</strong><ul>"
                        for citation in message["citations"]:
                            citations_html += f"<li>{citation['document_name']}, Page {citation['page']}</li>"
                        citations_html += "</ul></div>"
                    
                    st.markdown(f"<div class='chat-message assistant-message'><strong>Assistant:</strong> {response_text}{citations_html}</div>", unsafe_allow_html=True)
        
        # Query input
        st.markdown("<h2 class='sub-header'>Ask a Question</h2>", unsafe_allow_html=True)
        query = st.text_input("Type your question about the document:")
        
        if st.button("Submit") and query:
            # Add user message to state
            st.session_state.messages.append({"role": "user", "content": query})
            
            # Create a placeholder for the assistant's response
            response_placeholder = st.empty()
            response_placeholder.markdown("<div class='chat-message assistant-message'><strong>Assistant:</strong> Thinking...</div>", unsafe_allow_html=True)
            
            # Call API
            result = query_document(
                query=query, 
                document_id=st.session_state.document_id,
                conversation_id=st.session_state.conversation_id,
                require_citations=require_citations
            )
            
            if result.get("status") == "success":
                # Update conversation ID
                if "conversation_id" in result:
                    st.session_state.conversation_id = result.get("conversation_id")
                
                # Get response and citations
                response = result.get("response", {})
                answer = response.get("answer", "")
                citations = response.get("citations", [])
                
                # Add assistant message to state
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": answer,
                    "citations": citations
                })
                
                # Update the UI
                response_placeholder.empty()
                st.rerun()
            else:
                # Show error
                error_message = result.get("error_details", "Unknown error")
                response_placeholder.markdown(f"<div class='chat-message assistant-message'><strong>Assistant:</strong> Error: {error_message}</div>", unsafe_allow_html=True)
    else:
        # Prompt to upload a document
        st.info("Please upload a document to start the conversation.")
        
        # Demo information
        st.markdown("<h2 class='sub-header'>How It Works</h2>", unsafe_allow_html=True)
        st.markdown("""
        1. **Upload a Document**: Upload a PDF, DOCX, or TXT file from the sidebar.
        2. **Process the Document**: The system will extract text, split it into chunks, and generate embeddings.
        3. **Ask Questions**: Ask questions about the document content.
        4. **Get Contextual Answers**: The system retrieves relevant information from the document and generates accurate responses with citations.
        """)
        
        # Display supported features
        st.markdown("<h2 class='sub-header'>Supported Features</h2>", unsafe_allow_html=True)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Document Formats:**")
            st.markdown("- PDF (including scanned documents)")
            st.markdown("- Microsoft Word (DOCX)")
            st.markdown("- Text Files (TXT)")
        
        with col2:
            st.markdown("**Capabilities:**")
            st.markdown("- OCR for scanned documents")
            st.markdown("- Accurate contextual responses")
            st.markdown("- Citations for sources")
            st.markdown("- Conversation history")

if __name__ == "__main__":
    main()